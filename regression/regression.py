# -*- coding: utf-8 -*-
"""EE559-RegressionProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P11SCG07JGevu_vEKp7qFWV0oBgI0akU
"""

# Commented out IPython magic to ensure Python compatibility.
# necessary imports
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
from sklearn import preprocessing
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor
from sklearn import neighbors as nb
from sklearn import neural_network as nn
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.feature_selection import RFE, RFECV
from sklearn.model_selection import GridSearchCV, KFold, cross_val_score

df_train = pd.read_csv("student_performance_train.csv", sep=',')
df_test = pd.read_csv("student_performance_test.csv", sep=',')

df_train.head()

#converting categorical data to numeric  
cols=['school','sex','address','famsize','Pstatus','schoolsup','famsup','paid','activities','nursery','higher','internet',
      'romantic']
df=[df_train,df_test]
for x in df: 
    for col in cols:
        le = preprocessing.LabelEncoder()
        x[col] = le.fit_transform(x[col])
    x['Mjob'] = x['Mjob'].map({'teacher': 1, 'health': 2, 'services': 3, 'at_home': 4, 'other': 5})
    x['Fjob'] = x['Fjob'].map({'teacher': 1, 'health': 2, 'services': 3, 'at_home': 4, 'other': 5})
    x['reason'] = x['reason'].map({'home': 1, 'reputation': 2, 'course': 3, 'other': 4})
    x['guardian'] = x['guardian'].map({'mother': 1, 'father': 2, 'other': 3})

    x = x.sample(frac=1, random_state=1)

for x in df:
    x['average'] = x[['G1', 'G2']].mean(axis=1)

df_train

"""**Feature Selection: Step 1 (Identify Most Correlated or Most Important Features)**

---

**Select Best Features**

---

Maximum Correlation Method
"""

cor_matrix=df_train.corr()

cor_matrix

plt.rcParams.update({'figure.figsize':(20,20)})
sns.heatmap(cor_matrix,annot=True,cmap='Blues')
plt.show()

"""Random Forest Feature Importances Method (Code placed here since feature engineering and selection must happen on the entire dataset and not just the split dataset. Commented since the data has to be split first which is done below)"""

# random forest regression
# model_randomforest = RandomForestRegressor(n_estimators=100,max_depth=50)
# model_randomforest.fit(X_train, y_train)
# model_randomforest.score(X_train, y_train)

# a = list(X_train.keys())

# feature_imp = pd.Series(model_randomforest.feature_importances_,index=a).sort_values(ascending=False)

# plt.rcParams.update({'figure.figsize':(5,5)})
# sns.barplot(x=feature_imp,y=feature_imp.index)
# plt.show()

"""As we can see from the plot above, the features after an importance of 0.02 are not that effective and so about the top 15 features are the most important. Upon running the model for the 15 features versus all the features, the increase in accuracy is ~0.05 which is not a lot, which means that we can eliminate a good amount of features to get similar accuracy."""

# most_important_features = feature_imp[0:15]

# plt.rcParams.update({'figure.figsize':(5,5)})
# sns.barplot(x=most_important_features,y=most_important_features.index)
# plt.show()

# random forest regression
# model_randomforest = RandomForestRegressor(n_estimators=100,max_depth=50)
# model_randomforest.fit(X_train, y_train)
# y_pred = model_randomforest.predict(X_test)
# print(math.sqrt(mean_squared_error(y_test,y_pred)))
# print(model_randomforest.score(X_train, y_train))

"""Splitting Data into train input output and test input output"""

def split(df_train, df_test, target_column, drop_columns, dummy_columns):
  """
  function to split data into train and test and column that needs to be predicted
  function also drops columns specified and creates dummy columns as mentioned
  :params:
  :df_train: training data on which to split
  :df_test: testing data
  :target_column: feature to be predicted
  :drop_columns: columns to be dropped
  :dummy_columns: columns which need dummy variables to be creates
  """
  # dropping categorical non-binary features
  df_train_copy=df_train.copy()
  df_test_copy=df_test.copy()

  y_train = df_train_copy[target_column[0]]
  y_test = df_test_copy[target_column[0]]
  
  df_train_copy = df_train_copy.drop(columns=drop_columns, axis=1)
  df_test_copy = df_test_copy.drop(columns=drop_columns, axis=1)

  # declaring feature vector and target variable 
  X_train = df_train_copy
  X_test = df_test_copy

  # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)

  X_train = pd.get_dummies(X_train, columns=dummy_columns)
  X_test = pd.get_dummies(X_test, columns=dummy_columns)
  
  return X_train, X_test, y_train, y_test

"""Data for Trivial and Baseline models"""

X_train_tb_1, X_test_tb_1, y_train_tb_1, y_test_tb_1 = split(df_train, df_test, ['G1'], ['G1', 'G2', 'G3', 'reason', 'guardian', 'Mjob', 'Fjob', 'average'],[])

X_train_tb_2, X_test_tb_2, y_train_tb_2, y_test_tb_2 = split(df_train, df_test, ['G3'], ['G1', 'G2', 'G3', 'reason', 'guardian', 'Mjob', 'Fjob', 'average'])

X_train_tb_3, X_test_tb_3, y_train_tb_3, y_test_tb_3 = split(df_train, df_test, ['G1'], ['G1', 'G2', 'reason', 'guardian', 'Mjob', 'Fjob', 'average'])

"""Data for Models except Baseline and Trivial"""

X_train_1, X_test_1, y_train_1, y_test_1 = split(df_train, df_test, ['G1'], ['G1', 'G2', 'G3'], ['reason', 'guardian', 'Mjob', 'Fjob'])

X_train_2, X_test_2, y_train_2, y_test_2 = split(df_train, df_test, ['G3'], ['G1', 'G2', 'G3'], ['reason', 'guardian', 'Mjob', 'Fjob'])

X_train_3, X_test_3, y_train_3, y_test_3 = split(df_train, df_test, ['G3'], ['G3'], ['reason', 'guardian', 'Mjob', 'Fjob'])

"""Data after Feature Selection"""

X_train_fs_1, X_test_fs_1, y_train_fs_1, y_test_fs_1 = split(df_train, df_test, ['G1'], ['sex', 'age', 'address', 'famsize', 'Pstatus',
       'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',
       'romantic', 'famrel', 'health', 'G1', 'G2', 'G3'])

X_train_fs_2, X_test_fs_2, y_train_fs_2, y_test_fs_2 = split(df_train, df_test, ['G1'], ['sex', 'age', 'address', 'famsize', 'Pstatus',
       'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',
       'romantic', 'famrel', 'health', 'G1', 'G2', 'G3'])

X_train_fs_3, X_test_fs_3, y_train_fs_3, y_test_fs_3 = split(df_train, df_test, ['G1'], ['sex', 'age', 'address', 'famsize', 'Pstatus',
       'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',
       'romantic', 'famrel', 'health', 'G1', 'G2', 'G3'])

# combining all data into single list
X_train_all = [X_train_1, X_train_2, X_train_3]
X_test_all = [X_test_1, X_test_2, X_test_3]
y_train_all = [y_train_1, y_train_2, y_train_3]
y_test_all = [y_test_1, y_test_2, y_test_3]

X_train_fs_all = [X_train_fs_1, X_train_fs_2, X_train_fs_3]
X_test_fs_all = [X_test_fs_1, X_test_fs_2, X_test_fs_3]
y_train_fs_all = [y_train_fs_1, y_train_fs_2, y_train_fs_3]
y_test_fs_all = [y_test_fs_1, y_test_fs_2, y_test_fs_3]

"""**Trivial and Baseline System**

---

"""

def system(X_train, target_column, system=1, X_test=[], y_train=[], y_test=[]):
  """
  function which outputs score based on train data, test data, target column and chosen system
  :params:
  :system: 1 = trivial model, 2 = baseline 1 model, 3 = baseline 2 model
  """
  if system == 1:
    y_pred = [round(y_train.mean()) for _ in range(len(y_test))]
    y_test.columns = [target_column[0]]
    score = mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred)

  if system == 2:
    model = nb.KNeighborsRegressor(n_neighbors=1)
    model.fit(X_train, y_train)
    y_pred = pd.DataFrame(model.predict(X_test))
    score = mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred)

  if system == 3:
    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = pd.DataFrame(model.predict(X_test))
    score = mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred)
  return y_pred, score

def getScore(X_train, target_column, chosen_system, X_test, y_train, y_test):
  """
  function to get the score given the data and chosen system
  :params:
  :chosen_system: number of the system that is chosen
  """
  y, score = system(X_train, target_column, chosen_system, X_test, y_train, y_test)
  return score

print(getScore(X_train_1, ['G1'], 1, X_test_tb_1, y_train_tb_1, y_test_tb_1),
getScore(X_train_2, ['G3'], 1, X_test_tb_2, y_train_tb_2, y_test_tb_2),
getScore(X_train_3, ['G3'], 1, X_test_tb_3, y_train_tb_3, y_test_tb_3))

print(getScore(X_train_tb_1, ['G1'], 2, X_test_tb_1, y_train_tb_1, y_test_tb_1),
getScore(X_train_tb_2, ['G3'], 2, X_test_tb_2, y_train_tb_2, y_test_tb_2),
getScore(X_train_tb_3, ['G3'], 2, X_test_tb_3, y_train_tb_3, y_test_tb_3))

print(getScore(X_train_tb_1, ['G1'], 3, X_test_tb_1, y_train_tb_1, y_test_tb_1),
getScore(X_train_tb_2, ['G3'], 3, X_test_tb_2, y_train_tb_2, y_test_tb_2),
getScore(X_train_tb_3, ['G3'], 3, X_test_tb_3, y_train_tb_3, y_test_tb_3))

"""**KNN Regressor**

---
"""

best_params = []
accuracies = []
r2_scores = []

# running grid search on the knn regressor model on the train and using the best parameters to predict test
for i in range(len(X_train_fs_all)):
  model_knn = nb.KNeighborsRegressor()

  param_grid = {'n_neighbors':(1,2,3,4,5,6,7,8,9,10), 
              'p': (1,2,3),
              'algorithm':('kd_tree','brute','ball_tree','auto'),
              'weights': ('uniform', 'distance'),
              'metric': ("minkowski","euclidean", "manhattan", "chebyshev")}

  grid = GridSearchCV(model_knn, param_grid, cv=5, n_jobs = -1, verbose=1)

  grid_search=grid.fit(X_train_fs_all[i], y_train_fs_all[i])
  best_params.append(grid_search.best_params_)

  accuracy = grid_search.best_score_ *100
  accuracies.append(accuracy)

  y_pred = grid_search.predict(X_test_fs_all[i])
  y_t = y_test_fs_all[i]
  r2_scores.append(r2_score(y_t, y_pred))

accuracies, r2_scores, best_params

def getR2ScoreKNN(X_train, y_train, X_test, y_test, best_params):
  """
  function to get the r2 score for the knn model given the best parameters
  :params:
  :best_params: best parameters as obtained from the grid search
  """
  best_r2 = []

  for i in range(len(best_params)):
    best_model_knn = nb.KNeighborsRegressor(algorithm=best_params[i]['algorithm'], metric=best_params[i]['metric'],
                                              n_neighbors=best_params[i]['n_neighbors'], p=best_params[i]['p'], weights=best_params[i]['weights'])
    results = best_model_knn.fit(X_train[i], y_train[i])
    y_t = best_model_knn.predict(X_test[i])
    r2 = r2_score(y_t, y_test[i])
    best_r2.append(r2)
  return best_r2

print(getR2ScoreKNN(X_train_fs_all, y_train_fs_all, X_test_fs_all, y_test_fs_all, best_params))

"""**Support Vector Regressor**

---
"""

best_params = []
accuracies = []
r2_scores = []

# running grid search on the sv regressor model on the train and using the best parameters to predict test
for i in range(len(X_train_fs_all)):
  model_svr = SVR()

  param_grid = [{'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'kernel': ['rbf', 'linear']}]

  grid = GridSearchCV(model_svr, param_grid, cv=5, n_jobs = -1, verbose=1)

  grid_search=grid.fit(X_train_fs_all[i], y_train_fs_all[i])
  best_params.append(grid_search.best_params_)

  accuracy = grid_search.best_score_ *100
  accuracies.append(accuracy)

  y_pred = grid_search.predict(X_test_fs_all[i])
  y_t = y_test_fs_all[i]
  r2_scores.append(r2_score(y_t, y_pred))

accuracies, r2_scores, best_params

def getR2ScoreSVR(X_train, y_train, X_test, y_test, best_params):
  """
  similar to getR2ScoreKNN
  """
  best_r2 = []

  for i in range(len(best_params)):
    best_model_svr = SVR(kernel=best_params[i]['kernel'], C=best_params[i]['C'])
    results = best_model_svr.fit(X_train[i], y_train[i])
    y_t = best_model_svr.predict(X_test[i])
    r2 = r2_score(y_t, y_test[i])
    best_r2.append(r2)
  return best_r2

print(getR2ScoreSVR(X_train_fs_all, y_train_fs_all, X_test_fs_all, y_test_fs_all, best_params))

"""**ANN Regressor**

---
"""

best_params = []
accuracies = []
r2_scores = []

# running grid search on the mlp regressor model on the train and using the best parameters to predict test
for i in range(len(X_train_fs_all)):
  model_ann = nn.MLPRegressor()

  param_grid = [{"hidden_layer_sizes":[100,150,200], "activation":['relu', 'tanh', 'logistic'],
              "max_iter":[200,100,150,250,300,350,400],
              "momentum":[0.9,0.8,0.7], "n_iter_no_change":[10,20]}]
              
  grid = GridSearchCV(model_ann, param_grid, cv=5, n_jobs = -1, verbose=1)

  grid_search=grid.fit(X_train_fs_all[i], y_train_fs_all[i])
  best_params.append(grid_search.best_params_)

  accuracy = grid_search.best_score_ *100
  accuracies.append(accuracy)

  y_pred = grid_search.predict(X_test_fs_all[i])
  y_t = y_test_fs_all[i]
  r2_scores.append(r2_score(y_t, y_pred))

accuracies, r2_scores, best_params

def getR2ScoreANN(X_train, y_train, X_test, y_test, best_params):
  best_r2 = []

  for i in range(len(best_params)):
    best_model_ann = nb.MLPRegressor(hidden_layer_sizes=best_params[i]['hidden_layer_sizes'], activation=best_params[i]['activation'],
                                              max_iter=best_params[i]['max_iter'], momentum=best_params[i]['momentum'], n_iter_no_change=best_params[i]['n_iter_no_change'])
    results = best_model_ann.fit(X_train[i], y_train[i])
    y_t = best_model_ann.predict(X_test[i])
    r2 = r2_score(y_t, y_test[i])
    best_r2.append(r2)
  return best_r2

print(getR2ScoreANN(X_train_fs_all, y_train_fs_all, X_test_fs_all, y_test_fs_all, best_params))

"""**Decision Tree Regressor**

---
"""

best_params = []
accuracies = []
r2_scores = []

# running grid search on the DT regressor model on the train and using the best parameters to predict test
for i in range(len(X_train_fs_all)):
  model_decisiontree = DecisionTreeRegressor()

  param_grid = [{'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson']}]
              
  grid = GridSearchCV(model_decisiontree, param_grid, cv=5, n_jobs = -1, verbose=1)

  grid_search=grid.fit(X_train_fs_all[i], y_train_fs_all[i])
  best_params.append(grid_search.best_params_)

  accuracy = grid_search.best_score_ *100
  accuracies.append(accuracy)

  y_pred = grid_search.predict(X_test_fs_all[i])
  y_t = y_test_fs_all[i]
  r2_scores.append(r2_score(y_t, y_pred))

accuracies, r2_scores, best_params

def getR2ScoreDT(X_train, y_train, X_test, y_test, best_params):
  best_r2 = []

  for i in range(len(best_params)):
    best_model_dt = DecisionTreeRegressor(criterion=best_params[i]['criterion'])
    results = best_model_dt.fit(X_train[i], y_train[i])
    y_t = best_model_dt.predict(X_test[i])
    r2 = r2_score(y_t, y_test[i])
    best_r2.append(r2)
  return best_r2

print(getR2ScoreDT(X_train_fs_all, y_train_fs_all, X_test_fs_all, y_test_fs_all, best_params))

"""**Random Forest Regressor**

---
"""

# random forest regression
best_params = []
accuracies = []
r2_scores = []

# running grid search on the RF regressor model on the train and using the best parameters to predict test
for i in range(len(X_train_fs_all)):
  model_randomforest = RandomForestRegressor()

  param_grid = [{'n_estimators':[100,150,200,250,300,350,400,450], 'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson']}]
              
  grid = GridSearchCV(model_randomforest, param_grid, cv=5, n_jobs = -1, verbose=1)

  grid_search=grid.fit(X_train_fs_all[i], y_train_fs_all[i])
  best_params.append(grid_search.best_params_)

  accuracy = grid_search.best_score_ *100
  accuracies.append(accuracy)

  y_pred = grid_search.predict(X_test_fs_all[i])
  y_t = y_test_fs_all[i]
  r2_scores.append(r2_score(y_t, y_pred))

accuracies, r2_scores, best_params

def getR2ScoreRF(X_train, y_train, X_test, y_test, best_params):
  best_r2 = []

  for i in range(len(best_params)):
    best_model_rf = RandomForestRegressor(n_estimators=best_params[i]['n_estimators'], criterion=best_params[i]['criterion'])
    results = best_model_rf.fit(X_train[i], y_train[i])
    y_t = best_model_rf.predict(X_test[i])
    r2 = r2_score(y_t, y_test[i])
    best_r2.append(r2)
  return best_r2

print(getR2ScoreRF(X_train_fs_all, y_train_fs_all, X_test_fs_all, y_test_fs_all, best_params))

"""**XG Boost Regressor**

---
"""

# xgboost regression
best_params = []
accuracies = []
r2_scores = []

# running grid search on the xgboost regressor model on the train and using the best parameters to predict test
for i in range(len(X_train_fs_all)):
  model_xg = XGBRegressor()

  param_grid = [{'eta':[0.01,0.1,0.2,0.3,0.4,0.5], 'max_depth':[1,2,3,4,5,6,7]}]
              
  grid = GridSearchCV(model_xg, param_grid, cv=5, n_jobs = -1, verbose=1)

  grid_search=grid.fit(X_train_fs_all[i], y_train_fs_all[i])
  best_params.append(grid_search.best_params_)

  accuracy = grid_search.best_score_ *100
  accuracies.append(accuracy)

  y_pred = grid_search.predict(X_test_fs_all[i])
  y_t = y_test_fs_all[i]
  r2_scores.append(r2_score(y_t, y_pred))

accuracies, r2_scores, best_params

def getR2ScoreXG(X_train, y_train, X_test, y_test, best_params):
  best_r2 = []

  for i in range(len(best_params)):
    best_model_xg = XGBRegressor(eta=best_params[i]['eta'], max_depth=best_params[i]['max_depth'])
    results = best_model_xg.fit(X_train[i], y_train[i])
    y_t = best_model_xg.predict(X_test[i])
    r2 = r2_score(y_t, y_test[i])
    best_r2.append(r2)
  return best_r2

print(getR2ScoreXG(X_train_fs_all, y_train_fs_all, X_test_fs_all, y_test_fs_all, best_params))

model_xgb = XGBRegressor()
model_xgb.fit(X_train_3, y_train_3)

model_xgb.score(X_train_3, y_train_3)